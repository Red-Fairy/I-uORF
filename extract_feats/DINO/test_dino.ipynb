{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /sailhome/redfairy/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "dinoViT = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiscenesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataroot, n_scenes=5000, input_size=14*64):\n",
    "        \"\"\"Initialize this dataset class.\n",
    "\n",
    "        Parameters:\n",
    "            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n",
    "        \"\"\"\n",
    "        self.input_size = input_size\n",
    "        self.scenes = []\n",
    "        image_filenames = sorted(glob.glob(os.path.join(dataroot, '*.png')))  # root/00000_sc000_az00_el00.png\n",
    "        mask_filenames = sorted(glob.glob(os.path.join(dataroot, '*_mask.png')))\n",
    "        fg_mask_filenames = sorted(glob.glob(os.path.join(dataroot, '*_mask_for_moving.png')))\n",
    "        moved_filenames = sorted(glob.glob(os.path.join(dataroot, '*_moved.png')))\n",
    "        bg_mask_filenames = sorted(glob.glob(os.path.join(dataroot, '*_mask_for_bg.png')))\n",
    "        bg_in_mask_filenames = sorted(glob.glob(os.path.join(dataroot, '*_mask_for_providing_bg.png')))\n",
    "        changed_filenames = sorted(glob.glob(os.path.join(dataroot, '*_changed.png')))\n",
    "        bg_in_filenames = sorted(glob.glob(os.path.join(dataroot, '*_providing_bg.png')))\n",
    "        changed_filenames_set, bg_in_filenames_set = set(changed_filenames), set(bg_in_filenames)\n",
    "        bg_mask_filenames_set, bg_in_mask_filenames_set = set(bg_mask_filenames), set(bg_in_mask_filenames)\n",
    "        image_filenames_set, mask_filenames_set = set(image_filenames), set(mask_filenames)\n",
    "        fg_mask_filenames_set, moved_filenames_set = set(fg_mask_filenames), set(moved_filenames)\n",
    "        filenames_set = image_filenames_set - mask_filenames_set - fg_mask_filenames_set - moved_filenames_set - changed_filenames_set - bg_in_filenames_set - bg_mask_filenames_set - bg_in_mask_filenames_set\n",
    "        filenames = sorted(list(filenames_set))\n",
    "        self.n_scenes = n_scenes\n",
    "        self.n_img_each_scene = 4\n",
    "        for i in range(self.n_scenes):\n",
    "            scene_filenames = [x for x in filenames if 'sc{:04d}'.format(i) in x]\n",
    "            self.scenes.append(scene_filenames)\n",
    "\n",
    "    def _transform_encoder(self, img): # for ImageNet encoder\n",
    "        img = TF.resize(img, (self.input_size, self.input_size))\n",
    "        img = TF.to_tensor(img)\n",
    "        img = TF.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Return a data point and its metadata information.\n",
    "\n",
    "        Parameters:\n",
    "            index - - a random integer for data indexing, here it is scene_idx\n",
    "        \"\"\"\n",
    "        scene_idx = index\n",
    "        scene_filenames = self.scenes[scene_idx]\n",
    "        filenames = scene_filenames[:self.n_img_each_scene]\n",
    "        rets = []\n",
    "        for rd, path in enumerate(filenames):\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            img_data = self._transform_encoder(img)\n",
    "            rets.append((img_data, path))\n",
    "        paths = [x[1] for x in rets]\n",
    "        imgs = torch.stack([x[0] for x in rets])\n",
    "        return imgs, paths\n",
    "            \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of images in the dataset.\"\"\"\n",
    "        return self.n_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_size = 64\n",
    "input_size = 14*feat_size\n",
    "dataset = MultiscenesDataset('/viscam/projects/uorf-extension/datasets/room_diverse_nobg/train-1obj-manysize-trans-orange', n_scenes=50, input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 896, 896]) ['/viscam/projects/uorf-extension/datasets/room_diverse_nobg/train-1obj-manysize-trans-orange/00000_sc0000_az00.png', '/viscam/projects/uorf-extension/datasets/room_diverse_nobg/train-1obj-manysize-trans-orange/00001_sc0000_az01.png', '/viscam/projects/uorf-extension/datasets/room_diverse_nobg/train-1obj-manysize-trans-orange/00002_sc0000_az02.png', '/viscam/projects/uorf-extension/datasets/room_diverse_nobg/train-1obj-manysize-trans-orange/00003_sc0000_az03.png']\n",
      "(64, 64, 1024) /viscam/projects/uorf-extension/datasets/room_diverse_nobg/train-1obj-manysize-trans-orange/00000_sc0000_az00..npy\n",
      "(64, 64, 1024) /viscam/projects/uorf-extension/datasets/room_diverse_nobg/train-1obj-manysize-trans-orange/00001_sc0000_az01..npy\n",
      "(64, 64, 1024) /viscam/projects/uorf-extension/datasets/room_diverse_nobg/train-1obj-manysize-trans-orange/00002_sc0000_az02..npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:07<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 1024) /viscam/projects/uorf-extension/datasets/room_diverse_nobg/train-1obj-manysize-trans-orange/00003_sc0000_az03..npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out_channel = 1024\n",
    "for imgs, paths in tqdm(dataset):\n",
    "    print(imgs.shape, paths)\n",
    "    imgs = imgs.cuda()\n",
    "    with torch.no_grad():\n",
    "        feats = dinoViT.forward_features(imgs)['x_norm_patchtokens'].reshape(-1, feat_size, feat_size, out_channel)\n",
    "        feats = feats.cpu().numpy()\n",
    "    # save features\n",
    "    for rd, path in enumerate(paths):\n",
    "        path = path.replace('png', '.npy')\n",
    "        np.save(path, feats[rd])\n",
    "        print(feats[rd].shape, path)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
